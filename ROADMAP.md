# Roadmap

This simulator with working name **lilsim** is still in very early-stages development.
This document outlines an extensive roadmap of planned features.

#### Roadmap tasks:
- [ ] Make project adhere to defined clang tidy and clang format rules
- [ ] Proper installation
	- [ ] Make nice icon png with rounded edges
	- [ ] Install script(s) (platform dependent) that installs the program properly and makes it launchable from start menu (from whatever menu opens when pressing the "Windows" key)
	- [ ] Also make it launchable from terminal as simple command
- [ ] Make new project and new repo on Github with a better name for the simulator (drop working name "lilsim")
- [ ] Make a template repo showing how a development repo can look like
	- Separate repo in the same project on github
	- Showing how to set up CMake to install custom car model and how to use the Python SDK in the example notebook
- [ ] Examine if the Eigen dependency be removed
	- SE2 struct not used anymore
- [ ] Remove CarDefaults struct
- [ ] Make it compile and run on Windows
	- Jupyter notebook should also work
- [ ] Clean up the repository and improve assets
	- [ ] Make a generic default chassis skin
	- [ ] Make tire and chassis coloring look better
	- [ ] Update README.md with simple starting instructions
	- [ ] Make a nice GIF for the README that shows a pretty skidpad run with the default skin
- [ ] Sensor models
	- Will be another type of state beside cone positions and car state
	- [ ] Add range and bearing sensor model
		- Does not need generic modeling like the car, for now
		- Just hard-wired parameters that mimic a generic LiDAR perception module
			- Total FOV (H and V), scan speed, number of rings (5 for RS-M1), FOV per ring (overlap)
		- 2D Pose defined in car-local coordinate system
		- Provides timetamped cone measurements
		- False negatives and false positives
		- Future: more common false positives on simulated time keeping equipment
	- [ ] Add inertial sensor model
		- Also no generic modeling needed from the start
		- Perhaps different levels - IMU, VRU, AHRS
		- Noise parameters mostly
	- [ ] Add wheel speed sensors model
		- Should be fairly simple
		- Should be enough information in the obligatory states (x, y, yaw, front_right_wheel_angle and front_left_wheel_angle) to compute sensor output
		- Slip ratio ignored if no slip_ratio_* states are declared (* being front_left, rear_right etc.)
		- Would need effective_tire_radius state in order to output a rotational speed
	- [ ] For users that don't want to implement sensor fusion client-side, provide pre-fused sensor measurements as well
		- simple EKF
		- noisy velocity (in x and y) as well as yaw-rate of the car's center point (rear axle center) --- just enough for a client-side velocity motion model 
- [ ] Add tunable noise parameters for track parameters
	- uncorrelated noise for cone placement
	- noise for starting pose
	- Future: correlated noise for cone placement (like, skewed tracks)

**At this point, the simulator is ready for SLAM software development**

- [ ] ROS2 bridge
	- Quite important for usability for many FSD teams
	- Example C++ node(s) for synchronous control usage
- [ ] Simulated timekeeping equipment
	- Client application and GUI able to show laptimes, Accel/Skidpad times
		- Also part of state published by Sim module --- [ ] providing tick and timestamp when touched by car sprite, can only be activated again after car has fully left the beam
	- Generic left-right TK tripod pairs
	- Need their own nice pixel art, a slightly see-through red laser line is shown between them
	- May necessitate addition of **Events** as part of the scene
		- Events may also be useful for intermittent sensor readings
- [ ] Add marked 2D meshes as end-zones
	- Boolean state if car is inside it with all 4 wheel center points
	- Used to easily and automatically define success in driverless missions
		- Helpul for headless simulation
- [ ] Add a nice asphalt texture as background instead of blank grid
- [ ] Procedurally generated AutoX/Trackdrive tracks
	- including timekeeping equipment and large orange cones (start/finish line defined) 
	- [ ] Check out that [github python project](https://github.com/mvanlobensels/random-track-generator/tree/main), maybe it can be repurposed and extended
		- [ ] Rewrite in C++
- [ ] Implement a visualization plugin system
	- Plugin developer writes in "raw" WebGPU to draw their custom stuff in the Viewport
	- Always base these visualizations off of sim/car state or events from the selected data source (by default, the simulator), and allow modification of visuals by parameters
		- i.e. these plugins should not consider car model input or marker messages
		- If ROS 2 node connected via bridge wants to make a plugin viz show, it must send state or event (data source must be the ROS 2 bridge)
	- [ ] Implement example plugins that read ax, steering_wheel_angle (if available) and steering_wheel_rate (if available) to visualize the current viewport UI
		- if not available for currently selected model, don't show the bars and steering wheel at all
	- All compiled plugins should be listed where currently the "Simulated objects" tab is in the left side panel
		- So instead of simulated objects it will list all things that are visualized based on the actual state of the simulator, and events, not just physical objects in the sim
		- [ ] Add button like "load plugins" and when pressed it loads in all plugins that are installed in a given directory with fixed relative path to executable, similar to car model plugins 
			- All viz plugins that are found in the directory that can successfully be loaded in will then appear in the list, alongside the "Car" and "Cones" lines
- [ ] Add TS (Tractive System) and AS (Autonomous System) states (EBS states as well?)
	- Initially just TS and AS and purely for visualization purposes, and states are simply set by inputs, no logic inside sim
	- TSAL and ASSI Viz reacts to states
	- States separate from car model, not part of dynamics so logically separated
	- In the future:
		- TSMS, ASMS, TS activate (outside button) and RES controls (STOP and GO) as user inputs, TS and AS states are inferred from these inputs, with optional simulated delays 
		- TS must be on and AS must be in Driving, otherwise car model inputs are ignored
		- TS and AS states sent to client --- [ ] user software must react correctly to them
		- This would be educational for future ASRs
- [ ] Implement cone physics
	- Simple impulse 2D rigid body physics between circles and car (just a rectangle initially, or convex hull of Chassis sprite non-transparent pixels)
		- Later, collisions between cones should be supported
	- Constant friction coefficient for cones to make them slow down after being hit
	- If resulting speed of cone being hit is over a certain constant threshold, make it fall over
		- [ ] Add PNG pixel art sprites of regular cones and fallen over cones. Optionally a middle frame for falling to make animation smoother (but requires extra logic/state of cones) 
	- [ ] Automatically register DOO (Down Or Out) cones for automatic calculation of penalty time
	- Future (design choice): Fallen over cones may have different detection parameters for the simulated range-bearing sensors
- [ ] Define track bounds for Skidpad (2025+ version) and Accel
	- [ ] Automatically register OOB (Out Of Bounds) for automatic calculation of penalty time
- [ ] Simulated AMI (Autonomous Mission Indicator)
	- Client selects mission and mission is shown in viewport in cool UI --- digital 14-segment alphanumeric or dot display
	- Selected mission becomes part of scene state or metadata
- [ ] Make a simple library to help users write car model plugins with less effort
	- [ ] Implement a modular structure (rigid body, tires, aero, actuators) 
	- [ ] Implement different integrators (Euler, RK4)
	- [ ] Implement input time jitter, not just delay
- [ ] Add some better, more complicated car model plugins beyond the kinematic single-track
	- [ ] Dynamic single-track
	- [ ] Basic planar 4-wheel model
	- [ ] Complicated 4-wheel model with roll and pitch, advanced dynamics
		- It's okay if it cannot run in real-time
- [ ] Mac support
	- [ ] Make it compile and run on MacOS
	- Need help from someone that has a Mac, or maybe try it in Quickemu VM?
- [ ] Add a C++ SDK (beyond ROS 2 bridge)
	- C++ version of Python SDK with ZeroMQ client
	- [ ] Write small example program that uses it
- [ ] Add the ability to visualize external data, i.e., without running simulation
	- Ability to set data source as an MCAP file, or set the connected client as the data source
	- Ability to record simulation state/events into MCAP files automatically without clunky "rosbag record" terminal command required 
	- It would mean expanding the use case to make RViz/Rerun/Foxglove also obsolete
		- Would make lilsim the all-in-one
	- Important: markers are not part of state, they should never be recorded
		- Difference from ROS 2, where markers are topics just like everything else
		- Maybe this would change in the future so they could also be recorded and increase compatibility with ROS 2
		- I like that markers are more of an online thing, like regardless of it's showing recorded data or if it's live simulation data, you can "draw" on the viewport to show things. I don't really see markers as part of any state or an event
		- Visualizations based on state or events should be written as plug-ins, not use markers
	- Possibility to open a new window that shows timeline data for all inputs and states
	- Take inspiration from Rerun.io for this point
- [ ] Gaussian noise standard deviation parameters for...
	- Car model 
		- parameters (std. dev. defined for each one separately)
		- inputs?
	- Cone placement (same applied in x and y)
		- regular uncorrelated to start with
- [ ] Implement batched simulations, Sim without Viz (headless)
	- Store data in MCAP for each simulation instance
	- Add noise to parameters, cone placement, etc.
	- Procedurally generated tracks that differ between runs
		- probably better to sample from pre-generated data set
	- Run each step as fast as possible, no need to simulate real passing of time
	- Viewer for batched sim results
		- Provide averaged metrics (success rate, average speed, etc.)
		- Show list of all runs that can be sorted in order of several metrics, including DNF/Finish
			- Can select specific run to be visualized (scrub back and forth)

**At this point, a decent MVP has been reached**

### Possible future developments
- [ ] **Profiling**
    - Set it up with the tracy profiler to evaluate at least how fast the car model updates
- [ ] **Debug console**
	- Terminal inside the GUI that shows spdlog errors, warnings and info messages.
	- Little icon in bottom bar that lights up with yellow triangle or red circle for warnings and errors respectively, much like many IDEs/editors do.
- [ ] **Track editor**
	- Add ability to go into "Edit mode"
	- Make tracks with splines
		- Maybe start with a procedurally generated track, and then edit from there
	- Edit individual cone positions
	- Add ability to easily add bus stops, chicanes and slaloms
	- Implement ability to add timekeeping equipment
	- Implement ability to save track that is currently in scene to file (ImGuiFileDialogue) 
- [ ] **Simulink car modeling**
	- Make it easy for users to define car models using simulink
	- Simulink model compiled to C, then placed in a given directory together with a config file, script is run to generate glue and compile the model to a dynamic library (.dll/.so)
- [ ] **Car model validation**
	- New use case, comparing vehicle model (with current parameter set) with recorded vehicle data
		- Requires good vehicle data, ideally with RTK/PPK GNSS positioning
- [ ] **Upgrade to 3D**
	- Optionally render everything in 3D instead of the standard 2D viewport
	- Either Unity or Nvidia Omniverse framework (OpenUSD)
	- Allows driver-in-the loop with sim racing input hardware
		- Perhaps even VR support
	- A 3D scene would allow simulating raw LiDAR output based on ray-tracing on GPU
		- This is the most valuable feature from adding the third dimension, I believe
		- Requires a geometrically life-like scene with imperfections and competition-like environment
		- Requires realistic simulation of LiDAR hardware, noise in the right places and true-to-reality scanning behavior
			- Ideally recorded point clouds from any LiDAR should be able to be used as input to a model generator that generates a realistic model of that LiDAR for use in simulation
		- Since LiDAR simulation is the highest priority for 3D simulation, perhaps focus very little on realistic rendering, at least initially
	- A realistic rendering pipeline could allow realistic simulation of camera sensors
		- Lower priority than LiDAR, but potentially valuable